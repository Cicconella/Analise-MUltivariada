{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados Multivariados\n",
    "\n",
    "Podemos representar a matriz de dados da seguinte forma:\n",
    "\n",
    "$$ Y_{n \\times p} = \\begin{bmatrix}Y_{11} & \\dots & Y_{1p} \\\\ \\vdots & \\ddots & \\vdots \\\\ Y_{n1} & \\dots & Y_{np} \\end{bmatrix} $$\n",
    "\n",
    "Amostras: $i = 1, \\dots, n$\n",
    "\n",
    "Parâmetros: $j = 1, \\dots, p$\n",
    "\n",
    "Deste modo, \n",
    "\n",
    "$$ Y_{ij} = \\text{Resposta da i-ésima amostra para o j-ésimo parâmetro}  $$  \n",
    "\n",
    "\n",
    "Um exemplo de dados, medidas do crânio de 7 raças de cachorros pré-históricos (Manly, 2005):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X1   X2   X3   X4   X5   X6\n",
      "1  9.7 21.0 19.4  7.7 32.0 36.5\n",
      "2  8.1 16.7 18.3  7.0 30.3 32.9\n",
      "3 13.5 27.3 26.8 10.6 41.9 48.1\n",
      "4 11.5 24.3 24.5  9.3 40.0 44.6\n",
      "5 10.7 23.5 21.4  8.5 28.8 37.6\n",
      "6  9.6 22.6 21.1  8.3 34.4 43.1\n",
      "7 10.3 22.1 19.1  8.1 32.2 35.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>7</li>\n",
       "\t<li>6</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7\n",
       "\\item 6\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7\n",
       "2. 6\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 7 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "caes = read.table(\"MAE0330-Caes\", sep=\";\", header = T)\n",
    "print(caes)\n",
    "dim(caes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso,\n",
    "\n",
    "Amostras: n = 7\n",
    "\n",
    "Parâmetros: p = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estatísticas Descritivas\n",
    "\n",
    "#### Média da j-ésima variável:\n",
    "\n",
    "$$\\bar{Y_{j}} = \\frac{1}{n} \\sum_{i=1}^n Y_{ij} = \\frac{1}{n} (1'Y{.j})$$\n",
    "\n",
    "Assim, $\\bar{Y}$ é vetor de médias.\n",
    "\n",
    "#### Covariância entre variáveis j e j':\n",
    "\n",
    "$$s_{jj'} = \\frac{1}{n-1} \\sum_{i=1}^n (Y_{ij}-\\bar{Y_j})(Y_{ij'}-\\bar{Y_{j'}})$$\n",
    "\n",
    "Assim, $S$ é a matrix de variâncias e covariâncias de $Y$.\n",
    "\n",
    "#### Correlação entre as variáveis j e j':\n",
    "\n",
    "$$r_{jj'} = \\frac{s_{jj'}}{\\sqrt{s_{jj}}\\sqrt{s_{j'j'}}} = \\frac{\\sum_{i=1}^n (Y_{ij}-\\bar{Y_j})(Y_{ij'}-\\bar{Y_{j'}})}{\\sqrt{\\sum_{i=1}^n (Y_{ij}-\\bar{Y_j})^2}\\sqrt{\\sum_{i=1}^n (Y_{ij'}-\\bar{Y_{j'}})^2}}$$\n",
    "\n",
    "Assim, $S$ é a matrix de correlações de $Y$.\n",
    "\n",
    "#### Variância total de Y:\n",
    "\n",
    "$$ V.T. = tr(Y) - \\sum_{i=1}^n s_{ii} $$\n",
    "\n",
    "#### Variância generalizada de Y:\n",
    "\n",
    "$$ V.G. = |S| $$ \n",
    "\n",
    "#### Algumas considerações:\n",
    "\n",
    "- O valor de r deve ser entre -1 e 1\n",
    "\n",
    "- r mede a força da associação linear (0 é fraco e 1 é forte). O sinal indica a direção da associação.\n",
    "\n",
    "- O valor de $r_{jj'}$ não muda se as medidas da j-ésima variável mudam para $y_{ji} = ax_{ji}+b$ e os valores da j'-ésima variável muda para $y_{j'i} = cx_{j'i}+d$ para $i = 1,\\dots,n$ dadas que as constantes $a$ e $c$ possuem o mesmo sinal.\n",
    "\n",
    "- Covariância e correlação são muito sensíveis a outliers\n",
    "\n",
    "### No exemplo, \n",
    "\n",
    "Média para a variável $x_2$:\n",
    "\n",
    "$$ \\bar{Y}_{x_2} = \\frac{21+16.7+27.3+24.3+23.5+22.6+22.1}{7} = 22.5$$\n",
    "\n",
    "No R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X1       X2       X3       X4       X5       X6 \n",
      "10.48571 22.50000 21.51429  8.50000 34.22857 39.68571 \n"
     ]
    }
   ],
   "source": [
    "medias = colMeans(caes)               \n",
    "print(medias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O vetor \"medias\" pode ser descrito como o centróide de Y.\n",
    "\n",
    "Covariância para as variáveis $x_2$ e $x_4$:\n",
    "\n",
    "$$ s_{x_2x_4} = \\frac{1}{7-1} \\sum_{i=1}^7 (y_{ix_2}-22.5) (y_{ix_4}-8.5) = 3.59$$\n",
    "\n",
    "No R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3       X4        X5        X6\n",
      "X1 2.881429  5.251667  4.846905 1.933333  6.527143  7.739762\n",
      "X2 5.251667 10.556667  8.895000 3.593333 11.456667 15.583333\n",
      "X3 4.846905  8.895000  9.611429 3.508333 13.427857 16.305238\n",
      "X4 1.933333  3.593333  3.508333 1.356667  4.863333  5.920000\n",
      "X5 6.527143 11.456667 13.427857 4.863333 24.362381 24.680476\n",
      "X6 7.739762 15.583333 16.305238 5.920000 24.680476 31.518095\n"
     ]
    }
   ],
   "source": [
    "covariancias = cov(caes)\n",
    "print(covariancias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlação entre as variáveis $x_2$ e $x_4$:\n",
    "\n",
    "$$ r_{x_2x_4} = \\frac{\\sum_{i=1}^7  (y_{ix_2}-22.5) (y_{ix_4}-8.5)}{\\sqrt{\\sum_{i=1}^7 (y_{ix_2}-22.5)^2} \\sqrt{\\sum_{i=1}^7 (y_{ix_4}-8.5)^2}} = 0.9495$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1        X2        X3        X4        X5        X6\n",
      "X1 1.0000000 0.9522036 0.9210148 0.9778365 0.7790392 0.8121639\n",
      "X2 0.9522036 1.0000000 0.8830567 0.9495056 0.7143894 0.8543129\n",
      "X3 0.9210148 0.8830567 1.0000000 0.9715615 0.8775116 0.9368136\n",
      "X4 0.9778365 0.9495056 0.9715615 1.0000000 0.8459362 0.9053263\n",
      "X5 0.7790392 0.7143894 0.8775116 0.8459362 1.0000000 0.8906636\n",
      "X6 0.8121639 0.8543129 0.9368136 0.9053263 0.8906636 1.0000000\n"
     ]
    }
   ],
   "source": [
    "correlacoes = cor(caes)\n",
    "print(correlacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os valores de $y$ podem ser padronizados:\n",
    "\n",
    "$$ y_{ij}^* = \\frac{y_{ij}-\\bar{y}_j}{\\sqrt{s_{jj}}}$$\n",
    "\n",
    "Para $i = 1,...,7$ e $j = 1,...,6$\n",
    "\n",
    "Assim as variáveis estão centradas no zero e, deste modo, teremos que:\n",
    "\n",
    "$$ S^* = R^* = R $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1        X2        X3        X4        X5        X6\n",
      "X1 1.0000000 0.9522036 0.9210148 0.9778365 0.7790392 0.8121639\n",
      "X2 0.9522036 1.0000000 0.8830567 0.9495056 0.7143894 0.8543129\n",
      "X3 0.9210148 0.8830567 1.0000000 0.9715615 0.8775116 0.9368136\n",
      "X4 0.9778365 0.9495056 0.9715615 1.0000000 0.8459362 0.9053263\n",
      "X5 0.7790392 0.7143894 0.8775116 0.8459362 1.0000000 0.8906636\n",
      "X6 0.8121639 0.8543129 0.9368136 0.9053263 0.8906636 1.0000000\n",
      "          X1        X2        X3        X4        X5        X6\n",
      "X1 1.0000000 0.9522036 0.9210148 0.9778365 0.7790392 0.8121639\n",
      "X2 0.9522036 1.0000000 0.8830567 0.9495056 0.7143894 0.8543129\n",
      "X3 0.9210148 0.8830567 1.0000000 0.9715615 0.8775116 0.9368136\n",
      "X4 0.9778365 0.9495056 0.9715615 1.0000000 0.8459362 0.9053263\n",
      "X5 0.7790392 0.7143894 0.8775116 0.8459362 1.0000000 0.8906636\n",
      "X6 0.8121639 0.8543129 0.9368136 0.9053263 0.8906636 1.0000000\n",
      "          X1        X2        X3        X4        X5        X6\n",
      "X1 1.0000000 0.9522036 0.9210148 0.9778365 0.7790392 0.8121639\n",
      "X2 0.9522036 1.0000000 0.8830567 0.9495056 0.7143894 0.8543129\n",
      "X3 0.9210148 0.8830567 1.0000000 0.9715615 0.8775116 0.9368136\n",
      "X4 0.9778365 0.9495056 0.9715615 1.0000000 0.8459362 0.9053263\n",
      "X5 0.7790392 0.7143894 0.8775116 0.8459362 1.0000000 0.8906636\n",
      "X6 0.8121639 0.8543129 0.9368136 0.9053263 0.8906636 1.0000000\n"
     ]
    }
   ],
   "source": [
    "diagonal = sqrt(1/diag(covariancias))\n",
    "\n",
    "caesEstrela=caes\n",
    "\n",
    "for(i in 1:6){\n",
    "  b = (caes[,i]-medias[i])*diagonal[i]\n",
    "  caesEstrela[,i] = b\n",
    "}\n",
    "\n",
    "print(cov(caesEstrela))\n",
    "print(cor(caesEstrela))\n",
    "print(cor(caes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função *scale* do R faz a mesma coisa, mas eu queria deixar claro o cálculo. =P\n",
    "\n",
    "O centróide de $Y^*$ será o vetor de zeros e a variância total será igual ao valor de $p$, uma vez que a diagonal de $S^*$ contém apenas 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlação pode indicar uma relação indireta, por exemplo, se a variável A influencia B e C, mesmo que B e C sejam independentes, a correlação irá existir entre eles. Assim, podemos calcular a **Correlação Parcial** destas duas variáveis ($\\rho_{BC|A}$).\n",
    "\n",
    "#### Correlação parcial entre as variáveis $j$ e $j'$ dado $p$ variáveis:\n",
    "\n",
    "$$ \\rho_{jj'P \\backslash jj'} =  \\frac{-w_{jj'}}{\\sqrt{w_{jj}w_{j'j'}}}$$\n",
    "\n",
    "Sendo que a matriz $W$ é dada pela inversa da matriz $S$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X1         X2         X3         X4         X5         X6\n",
      "X1 -1.0000000  0.8101713  0.4771876  0.7061076  0.7124201 -0.9127644\n",
      "X2  0.8101713 -1.0000000 -0.7213236 -0.1992454 -0.8414502  0.8919502\n",
      "X3  0.4771876 -0.7213236 -1.0000000  0.1973347 -0.5309113  0.6757264\n",
      "X4  0.7061076 -0.1992454  0.1973347 -1.0000000 -0.2226388  0.4753696\n",
      "X5  0.7124201 -0.8414502 -0.5309113 -0.2226388 -1.0000000  0.8364454\n",
      "X6 -0.9127644  0.8919502  0.6757264  0.4753696  0.8364454 -1.0000000\n"
     ]
    }
   ],
   "source": [
    "inversaCov = solve(covariancias)\n",
    "\n",
    "corMarg = inversaCov\n",
    "\n",
    "for(i in 1:nrow(inversaCov)){\n",
    "  for(j in 1:ncol(inversaCov)){\n",
    "    corMarg[i,j] = -corMarg[i,j]/sqrt(inversaCov[i,i]*inversaCov[j,j]) \n",
    "  }\n",
    "}\n",
    "\n",
    "print(corMarg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deste modo, temos que, por exemplo, as variáveis $x_1$ e $x_3$ que tinham uma correlação de 92%, e sem o efeito das outras variáveis, pasosu a ter apenas 47% de correlação. A diagonal será definida como positiva.\n",
    "\n",
    "A **correlação parcial** pode ser calculada de outras formas, como por exemplo, por regressão linear.\n",
    "\n",
    "\n",
    "# Medidas de Distância\n",
    "\n",
    "Dado o ponto $P$ em um espaço n-dimensional, $P=(x_1,\\dots, x_n)$, sua distância eucliadiana da origem pode ser descrita como:\n",
    "\n",
    "$$ d(O, P) = \\sqrt{x_1^2 + \\dots + x_n^2} $$\n",
    "\n",
    "E sua distância para um ponto $Q$, $Q=(y_1,\\dots, y_n)$, dado por:\n",
    "\n",
    "$$ d(P, Q) = \\sqrt{(x_1-y_1)^2 + \\dots + (x_n -y_n)^2} $$\n",
    "\n",
    "Essa definição de $d$ descreve uma hiperesfera (esfera para n=2). \n",
    "\n",
    "Entretanto, cada coordenada contribui da mesma forma para a distância euclidiana, impedindo a possibilidade de dar pesos as variáveis.\n",
    "\n",
    "##### Distância euclidiana supõe variáveis independentes e variâncias homogêneas.\n",
    "\n",
    "## Distâncias estatísticas\n",
    "\n",
    "Distância que leva em consideração as diferenças de variação e o grau de correlação.\n",
    "\n",
    "Uma forma é calcular a distância euclidiana com os valores padronizados (Distância de Pearson):\n",
    "\n",
    "$$ d(O, P) = \\sqrt{\\frac{x_1^2}{s_{11}} + \\dots + \\frac{x_n^2}{s_{nn}}} $$\n",
    "\n",
    "$$ d(P,Q) = \\sqrt{\\frac{(x_1-y_1)^2}{s_{11}} + \\dots + \\frac{(x_n-y_n)^2}{s_{nn}}} $$\n",
    "\n",
    "Entretanto, essas distâncias, como esperado quando $s$ é diferente para cada variável, formam elipsóides. Assim, supõe-se que as variáveis são independentes.\n",
    "\n",
    "#### Padronizar as variáveis é solução quando supõe-se heterocedasticidade e independência.  \n",
    "\n",
    "**Quando as variáveis são correlacionadas e com variabilidade diferentes**, uma solução é a distância de Mahalanobis. \n",
    "\n",
    "Considera-se duas variáves: $x_1$ e $x_2$ correlacionadas e com variâncias diferentes. Rotaciona-se o sistema de eixos de modo que um dos eixos descreva o eixo de maior variância.\n",
    "\n",
    "Assim:\n",
    "\n",
    "$$ d(O,P) = \\sqrt{\\frac{\\tilde{x}^2_1}{\\tilde{s}_{11}}+\\frac{\\tilde{x}^2_2}{\\tilde{s}_{22}}} $$\n",
    "\n",
    "Em que:\n",
    "\n",
    "$$\\tilde{x}_1 = x_1 cos(\\theta) + x_2 sin(\\theta) $$\n",
    "$$\\tilde{x}_1 = -x_1 sin(\\theta) + x_2 cos(\\theta) $$\n",
    "\n",
    "Gerando,\n",
    "\n",
    "$$ d(O,P) = \\sqrt{a_{11}x^2_1 + 2a_{12}x_1x_2 + a_{22}x_2^2}$$\n",
    "\n",
    "Em que, $a$ são valores obtidos de acordo com o ângulo $\\theta$.\n",
    "\n",
    "Generalizando,\n",
    "\n",
    "$$ d_M^2(P,\\mu) = (Y_{px1}-\\mu_{px1})'S(Y_{px1}-\\mu_{px1})$$\n",
    "\n",
    "### Propriedades:\n",
    "\n",
    "- $ d(P,Q) = d(Q,P) $\n",
    "- $ d(P,Q) > 0 \\text{ se } P \\neq 0$\n",
    "- $ d(P,Q) = 0 \\text{ se } P=Q$\n",
    "- $ d(P,Q) \\leq d(P,R)+d(R,Q)$ para $R$ entre $P$ e $Q$\n",
    "\n",
    "### Por que usar as distâncias?\n",
    "\n",
    "1. Diagnóstico de observações atípicas (Distância da observação à média);\n",
    "2. Técnicas de agrupamento.\n",
    "\n",
    "Por exemplo, usando a distância de Malahanobis, podemos usar o seguinte teste para identificar outliers:  $d^2_M \\sim \\chi ^2_p$.\n",
    "\n",
    "No caso do exemplo dos cães, nenhum ponto é considerado outlier, pois, para $\\alpha=0.05$ todas as distâncias (ao quadrado) são abaixo de 12,59 (Linha no gráfico).\n",
    "\n",
    "Se a matriz de covariâncias não for arredondada, espera-se que as distâncias dos pontos para o centróide sejam todas iguais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.6341095 4.1650023 3.1278595 2.6621452 6.8209763 4.0234439 5.1738335\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nEBIgQEiAACEBAoQECPx/2DbYUp+/xrgAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = mahalanobis(caes, medias, round(covariancias))\n",
    "print(dm)\n",
    "plot(dm, ylim=c(1,13), ylab=\"Distancia de Mahalanobis ao Quadrado\")\n",
    "abline(qchisq(.95, df=6), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um exemplo utilizando os dados dos cães:\n",
    "\n",
    "Considerando a amostra 7 como o cão ancestral e os outros caẽs como o grupo de cães modernos, podemos calcular a distância entre o ancestral e os modernos de diferentes maneiras:\n",
    "\n",
    "Adotando a distância de Malahanobis, uma vez que as variáveis são correlacionadas e com variâncias heterogêneas, a distância média é a média das distâncias de cada cão moderno com o cão ancestral: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X1   X2   X3   X4   X5   X6\n",
      "1  9.7 21.0 19.4  7.7 32.0 36.5\n",
      "2  8.1 16.7 18.3  7.0 30.3 32.9\n",
      "3 13.5 27.3 26.8 10.6 41.9 48.1\n",
      "4 11.5 24.3 24.5  9.3 40.0 44.6\n",
      "5 10.7 23.5 21.4  8.5 28.8 37.6\n",
      "6  9.6 22.6 21.1  8.3 34.4 43.1\n",
      "     X1    X2    X3   X4    X5    X6\n",
      "X1 3.45  6.28  5.71 2.30  7.74  9.08\n",
      "X2 6.28 12.63 10.45 4.27 13.56 18.26\n",
      "X3 5.71 10.45 10.17 3.98 14.97 16.93\n",
      "X4 2.30  4.27  3.98 1.59  5.65  6.67\n",
      "X5 7.74 13.56 14.97 5.65 28.27 27.40\n",
      "X6 9.08 18.26 16.93 6.67 27.40 32.70\n",
      "       1        2        3        4        5        6 \n",
      "10.89502 11.76207 11.57914 11.62601 11.52028 11.99944 \n",
      "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
      "  10.90   11.53   11.60   11.56   11.73   12.00 \n"
     ]
    }
   ],
   "source": [
    "moderno = caes[-7,]\n",
    "print(moderno)\n",
    "covarianciaModerno = round(var(moderno),2)\n",
    "print(covarianciaModerno)\n",
    "vetor = as.numeric(caes[7,])\n",
    "maha = mahalanobis(moderno, vetor, covarianciaModerno)\n",
    "maha = sqrt(maha) #Distancia de Mahalanobis eh dada ao quadrado\n",
    "print(maha)\n",
    "print(summary(maha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deste modo, temos que a distância média é 11.56, a distância mínima (cão moderno mais próximo do ancestral) é o 5 a distância máxima (cão moderno mais distante do ancestral) é o 6.\n",
    "\n",
    "Outra distância possível é entre o centróide dos cães modernos e o ancestral (11.39):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1        X2        X3        X4        X5        X6 \n",
      "10.516667 22.566667 21.916667  8.566667 34.566667 40.466667 \n",
      "[1] 11.39047\n"
     ]
    }
   ],
   "source": [
    "centroide = colMeans(moderno)\n",
    "print(centroide)\n",
    "\n",
    "maha2 = mahalanobis(centroide, vetor, covarianciaModerno)\n",
    "print(sqrt(maha2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Análise de Componentes Principais\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "- Reduzir a dimensionalidade dos dados\n",
    "- Descrever a variabilidade de variáveis correlacionadas\n",
    "\n",
    "### Álgebra\n",
    "\n",
    "A primeira componente principal (CP1) é a combinação linear das observações que descreve a maior variância dos dados. A segunda componente principal (CP2) descreve a segunda maior variância dos dados ortogonal à primeira componente, e assim por diante até a n-énesima componente ($n$ = número de variáveis).\n",
    "\n",
    "$$ PC = a_{11}x_1 + a_{12}x_2 + \\dots + a_{1q}x_q$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
